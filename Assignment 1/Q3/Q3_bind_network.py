#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Q3: Bind Network å®ç°
åŸºäºè®ºæ–‡ã€ŠImageBind-LLM: Multi-modality Instruction Tuningã€‹ä¸­çš„å›¾3
å®ç°å›¾åƒç‰¹å¾åˆ°è½¬æ¢åå›¾åƒç‰¹å¾çš„æ˜ å°„ç½‘ç»œ
"""

import torch
import torch.nn as nn
import torch.nn.functional as F


class RMSNorm(nn.Module):
    """Root Mean Square Layer Normalization"""
    def __init__(self, dim: int, eps: float = 1e-6):
        super().__init__()
        self.eps = eps
        self.weight = nn.Parameter(torch.ones(dim))

    def forward(self, x):
        # RMS normalization
        norm_x = x.norm(dim=-1, keepdim=True) * (x.shape[-1] ** -0.5)
        return self.weight * (x / (norm_x + self.eps))


class BindNetwork(nn.Module):
    """
    Bind Network å®ç°
    
    ç½‘ç»œç»“æ„ï¼š
    1. åˆå§‹çº¿æ€§å˜æ¢ (W0)
    2. ä¸‰ä¸ªé‡å¤çš„æ ¸å¿ƒå— (x3)ï¼Œæ¯ä¸ªåŒ…å«ï¼š
       - å½’ä¸€åŒ– (Norm)
       - å¹¶è¡Œè·¯å¾„ï¼šW2 å’Œ (W1 + SiLU)
       - å…ƒç´ çº§ä¹˜æ³• (âŠ—)
       - çº¿æ€§å˜æ¢ (W3)
       - æ®‹å·®è¿æ¥ (âŠ•)
    
    è¾“å…¥: image_feature (å›¾åƒç‰¹å¾)
    è¾“å‡º: transformed_image_feature (è½¬æ¢åçš„å›¾åƒç‰¹å¾)
    """
    
    def __init__(self, input_dim: int = 1024, hidden_dim: int = 4096, 
                 num_blocks: int = 3, use_rms_norm: bool = True):
        """
        åˆå§‹åŒ– Bind Network
        
        Args:
            input_dim: è¾“å…¥ç‰¹å¾ç»´åº¦ (é»˜è®¤ 1024ï¼Œå¯¹åº” ImageBind è¾“å‡º)
            hidden_dim: éšè—å±‚ç»´åº¦ (é»˜è®¤ 4096ï¼Œå¯¹åº” LLaMA ç»´åº¦)
            num_blocks: é‡å¤å—çš„æ•°é‡ (é»˜è®¤ 3)
            use_rms_norm: æ˜¯å¦ä½¿ç”¨ RMSNorm (é»˜è®¤ True)
        """
        super().__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.num_blocks = num_blocks
        
        # åˆå§‹çº¿æ€§å˜æ¢ W0
        self.W0 = nn.Linear(input_dim, hidden_dim)
        
        # å®šä¹‰å½’ä¸€åŒ–å±‚ç±»å‹
        if use_rms_norm:
            norm_layer = RMSNorm
        else:
            norm_layer = nn.LayerNorm
        
        # ä¸‰ä¸ªé‡å¤çš„æ ¸å¿ƒå—
        self.norms = nn.ModuleList([
            norm_layer(hidden_dim) for _ in range(num_blocks)
        ])
        
        self.W1_layers = nn.ModuleList([
            nn.Linear(hidden_dim, hidden_dim * 4) for _ in range(num_blocks)
        ])
        
        self.W2_layers = nn.ModuleList([
            nn.Linear(hidden_dim, hidden_dim * 4) for _ in range(num_blocks)
        ])
        
        self.W3_layers = nn.ModuleList([
            nn.Linear(hidden_dim * 4, hidden_dim) for _ in range(num_blocks)
        ])
        
        # SiLU æ¿€æ´»å‡½æ•°
        self.silu = nn.SiLU()
    
    def forward(self, image_feature):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            image_feature: è¾“å…¥å›¾åƒç‰¹å¾ [batch_size, seq_len, input_dim]
            
        Returns:
            transformed_image_feature: è½¬æ¢åçš„å›¾åƒç‰¹å¾ [batch_size, seq_len, hidden_dim]
        """
        # åˆå§‹çº¿æ€§å˜æ¢ W0
        x = self.W0(image_feature)
        
        # ä¸‰ä¸ªé‡å¤çš„æ ¸å¿ƒå—
        for i in range(self.num_blocks):
            # ä¿å­˜è¾“å…¥ç”¨äºæ®‹å·®è¿æ¥
            residual = x
            
            # å½’ä¸€åŒ–
            x_norm = self.norms[i](x)
            
            # å¹¶è¡Œè·¯å¾„
            # è·¯å¾„1: W2
            w2_out = self.W2_layers[i](x_norm)
            
            # è·¯å¾„2: W1 + SiLU
            w1_out = self.W1_layers[i](x_norm)
            silu_out = self.silu(w1_out)
            
            # å…ƒç´ çº§ä¹˜æ³• (âŠ—)
            gate_out = w2_out * silu_out
            
            # çº¿æ€§å˜æ¢ W3
            x = self.W3_layers[i](gate_out)
            
            # æ®‹å·®è¿æ¥ (âŠ•)
            x = x + residual
        
        return x


def test_bind_network():
    """æµ‹è¯• Bind Network çš„åŠŸèƒ½"""
    print("æµ‹è¯• Bind Network...")
    
    # åˆ›å»ºæ¨¡å‹
    model = BindNetwork(input_dim=1024, hidden_dim=4096, num_blocks=3)
    
    # æµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 1
    input_dim = 1024
    
    # æ¨¡æ‹Ÿ ImageBind è¾“å‡ºçš„å›¾åƒç‰¹å¾
    image_feature = torch.randn(batch_size, seq_len, input_dim)
    
    print(f"è¾“å…¥å½¢çŠ¶: {image_feature.shape}")
    
    # å‰å‘ä¼ æ’­
    with torch.no_grad():
        output = model(image_feature)
    
    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
    
    # éªŒè¯è¾“å‡ºå½¢çŠ¶
    expected_shape = (batch_size, seq_len, 4096)
    assert output.shape == expected_shape, f"è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…: {output.shape} vs {expected_shape}"
    
    print("âœ“ Bind Network æµ‹è¯•é€šè¿‡!")
    
    # æ‰“å°æ¨¡å‹å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    print(f"æ€»å‚æ•°æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°æ•°é‡: {trainable_params:,}")
    
    return model


def create_simplified_bind_network():
    """
    åˆ›å»ºç®€åŒ–ç‰ˆæœ¬çš„ Bind Networkï¼Œæ›´æ¥è¿‘å‚è€ƒä»£ç çš„ç»“æ„
    """
    class SimplifiedBindNetwork(nn.Module):
        def __init__(self, input_dim: int = 1024, hidden_dim: int = 4096):
            super().__init__()
            
            # æŠ•å½±å±‚ (å¯¹åº”å‚è€ƒä»£ç ä¸­çš„ image_bind_proj)
            self.proj = nn.Linear(input_dim, hidden_dim)
            
            # ä¸‰ä¸ªé‡å¤å— (å¯¹åº”å‚è€ƒä»£ç ä¸­çš„ä¸‰ä¸ª image_bind_norm/f1/f2/f3)
            self.norm_1 = RMSNorm(hidden_dim)
            self.f1_1 = nn.Linear(hidden_dim, hidden_dim * 4)
            self.f2_1 = nn.Linear(hidden_dim * 4, hidden_dim)
            self.f3_1 = nn.Linear(hidden_dim, hidden_dim * 4)
            
            self.norm_2 = RMSNorm(hidden_dim)
            self.f1_2 = nn.Linear(hidden_dim, hidden_dim * 4)
            self.f2_2 = nn.Linear(hidden_dim * 4, hidden_dim)
            self.f3_2 = nn.Linear(hidden_dim, hidden_dim * 4)
            
            self.norm_3 = RMSNorm(hidden_dim)
            self.f1_3 = nn.Linear(hidden_dim, hidden_dim * 4)
            self.f2_3 = nn.Linear(hidden_dim * 4, hidden_dim)
            self.f3_3 = nn.Linear(hidden_dim, hidden_dim * 4)
        
        def forward(self, image_feature):
            # æŠ•å½±åˆ°éšè—ç»´åº¦
            x = self.proj(image_feature)
            
            # ç¬¬ä¸€ä¸ªå—
            x_norm = self.norm_1(x)
            x = x + self.f2_1(F.silu(self.f1_1(x_norm)) * self.f3_1(x_norm))
            
            # ç¬¬äºŒä¸ªå—
            x_norm = self.norm_2(x)
            x = x + self.f2_2(F.silu(self.f1_2(x_norm)) * self.f3_2(x_norm))
            
            # ç¬¬ä¸‰ä¸ªå—
            x_norm = self.norm_3(x)
            x = x + self.f2_3(F.silu(self.f1_3(x_norm)) * self.f3_3(x_norm))
            
            return x
    
    return SimplifiedBindNetwork


if __name__ == "__main__":
    print("=" * 60)
    print("Q3: Bind Network å®ç°æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•æ ‡å‡†ç‰ˆæœ¬
    print("\n1. æµ‹è¯•æ ‡å‡† Bind Network:")
    model1 = test_bind_network()
    
    # æµ‹è¯•ç®€åŒ–ç‰ˆæœ¬
    print("\n2. æµ‹è¯•ç®€åŒ– Bind Network:")
    SimplifiedBindNetwork = create_simplified_bind_network()
    model2 = SimplifiedBindNetwork(input_dim=1024, hidden_dim=4096)
    
    # æµ‹è¯•ç®€åŒ–ç‰ˆæœ¬
    image_feature = torch.randn(2, 1, 1024)
    with torch.no_grad():
        output2 = model2(image_feature)
    
    print(f"ç®€åŒ–ç‰ˆæœ¬è¾“å‡ºå½¢çŠ¶: {output2.shape}")
    
    total_params2 = sum(p.numel() for p in model2.parameters())
    print(f"ç®€åŒ–ç‰ˆæœ¬å‚æ•°æ•°é‡: {total_params2:,}")
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼Bind Network å®ç°æˆåŠŸï¼")
    print("=" * 60)
